{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f364c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eager exc False\n",
      "tensorflow: 2.4.1\n",
      "keras version\n",
      "2.4.3\n",
      "tensorflow version\n",
      "2.4.1\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method PosteriorLayer.call of <layers.PosteriorLayer object at 0x7fe4834f7670>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method PosteriorLayer.call of <layers.PosteriorLayer object at 0x7fe4834f7670>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:From /home/lm/files/sw/cond3/envs/py39/lib/python3.9/site-packages/tensorflow/python/autograph/converters/directives.py:130: The name tf.keras.backend.get_session is deprecated. Please use tf.compat.v1.keras.backend.get_session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-06 16:12:16.404920: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2023-02-06 16:12:16.405164: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-06 16:12:16.406887: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "2023-02-06 16:12:16.416937: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:196] None of the MLIR optimization passes are enabled (registered 0 passes)\n",
      "2023-02-06 16:12:16.440338: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2496000000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 128000 samples, validate on 32000 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lm/files/sw/cond3/envs/py39/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:2325: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128000/128000 - 6s - loss: 0.0748 - classifier_loss: 0.7012 - adversary_loss: 0.0237 - val_loss: -2.0660e-01 - val_classifier_loss: 0.6998 - val_adversary_loss: -6.8716e-02\n",
      "Epoch 2/100\n",
      "128000/128000 - 2s - loss: -1.7520e+00 - classifier_loss: 0.7054 - adversary_loss: -5.9707e-01 - val_loss: -4.0297e+00 - val_classifier_loss: 0.7214 - val_adversary_loss: -1.3412e+00\n",
      "Epoch 3/100\n",
      "128000/128000 - 2s - loss: -4.4410e+00 - classifier_loss: 0.7228 - adversary_loss: -1.4811e+00 - val_loss: -4.4705e+00 - val_classifier_loss: 0.7353 - val_adversary_loss: -1.4924e+00\n",
      "Epoch 4/100\n",
      "128000/128000 - 2s - loss: -4.3468e+00 - classifier_loss: 0.7681 - adversary_loss: -1.4468e+00 - val_loss: -4.1455e+00 - val_classifier_loss: 0.8171 - val_adversary_loss: -1.3817e+00\n",
      "Epoch 5/100\n",
      "128000/128000 - 2s - loss: -4.0498e+00 - classifier_loss: 0.8702 - adversary_loss: -1.3502e+00 - val_loss: -4.0004e+00 - val_classifier_loss: 0.9178 - val_adversary_loss: -1.3316e+00\n",
      "Epoch 6/100\n",
      "128000/128000 - 2s - loss: -4.1386e+00 - classifier_loss: 0.9395 - adversary_loss: -1.3810e+00 - val_loss: -4.3225e+00 - val_classifier_loss: 0.9407 - val_adversary_loss: -1.4393e+00\n",
      "Epoch 7/100\n",
      "128000/128000 - 2s - loss: -4.6861e+00 - classifier_loss: 0.9234 - adversary_loss: -1.5654e+00 - val_loss: -5.6094e+00 - val_classifier_loss: 0.8815 - val_adversary_loss: -1.8718e+00\n",
      "Epoch 8/100\n",
      "128000/128000 - 2s - loss: -6.8544e+00 - classifier_loss: 0.8608 - adversary_loss: -2.2865e+00 - val_loss: -7.1329e+00 - val_classifier_loss: 0.8324 - val_adversary_loss: -2.3808e+00\n",
      "Epoch 9/100\n",
      "128000/128000 - 2s - loss: -7.2007e+00 - classifier_loss: 0.8234 - adversary_loss: -2.4018e+00 - val_loss: -7.1443e+00 - val_classifier_loss: 0.7961 - val_adversary_loss: -2.3832e+00\n",
      "Epoch 10/100\n",
      "128000/128000 - 2s - loss: -7.2017e+00 - classifier_loss: 0.7804 - adversary_loss: -2.4002e+00 - val_loss: -7.1458e+00 - val_classifier_loss: 0.7611 - val_adversary_loss: -2.3871e+00\n",
      "Epoch 11/100\n",
      "128000/128000 - 2s - loss: -7.1940e+00 - classifier_loss: 0.7492 - adversary_loss: -2.3988e+00 - val_loss: -7.1363e+00 - val_classifier_loss: 0.7288 - val_adversary_loss: -2.3826e+00\n",
      "Epoch 12/100\n",
      "128000/128000 - 2s - loss: -7.1850e+00 - classifier_loss: 0.7242 - adversary_loss: -2.3964e+00 - val_loss: -7.1308e+00 - val_classifier_loss: 0.7115 - val_adversary_loss: -2.3738e+00\n",
      "Epoch 13/100\n",
      "128000/128000 - 2s - loss: -7.1772e+00 - classifier_loss: 0.7061 - adversary_loss: -2.3931e+00 - val_loss: -7.1144e+00 - val_classifier_loss: 0.6954 - val_adversary_loss: -2.3662e+00\n",
      "Epoch 14/100\n",
      "128000/128000 - 2s - loss: -7.1690e+00 - classifier_loss: 0.6929 - adversary_loss: -2.3884e+00 - val_loss: -7.1127e+00 - val_classifier_loss: 0.6813 - val_adversary_loss: -2.3781e+00\n",
      "Epoch 15/100\n",
      "128000/128000 - 2s - loss: -7.1602e+00 - classifier_loss: 0.6829 - adversary_loss: -2.3865e+00 - val_loss: -7.1021e+00 - val_classifier_loss: 0.6755 - val_adversary_loss: -2.3634e+00\n",
      "Epoch 16/100\n",
      "128000/128000 - 2s - loss: -7.1530e+00 - classifier_loss: 0.6762 - adversary_loss: -2.3829e+00 - val_loss: -7.0989e+00 - val_classifier_loss: 0.6694 - val_adversary_loss: -2.3682e+00\n",
      "Epoch 17/100\n",
      "128000/128000 - 2s - loss: -7.1471e+00 - classifier_loss: 0.6708 - adversary_loss: -2.3822e+00 - val_loss: -7.0824e+00 - val_classifier_loss: 0.6643 - val_adversary_loss: -2.3636e+00\n",
      "Epoch 18/100\n",
      "128000/128000 - 2s - loss: -7.1439e+00 - classifier_loss: 0.6661 - adversary_loss: -2.3823e+00 - val_loss: -7.0831e+00 - val_classifier_loss: 0.6597 - val_adversary_loss: -2.3636e+00\n",
      "Epoch 19/100\n",
      "128000/128000 - 2s - loss: -7.1401e+00 - classifier_loss: 0.6614 - adversary_loss: -2.3804e+00 - val_loss: -7.0891e+00 - val_classifier_loss: 0.6541 - val_adversary_loss: -2.3627e+00\n",
      "Epoch 20/100\n",
      "128000/128000 - 2s - loss: -7.1388e+00 - classifier_loss: 0.6567 - adversary_loss: -2.3787e+00 - val_loss: -7.0825e+00 - val_classifier_loss: 0.6509 - val_adversary_loss: -2.3492e+00\n",
      "Epoch 21/100\n",
      "128000/128000 - 2s - loss: -7.1428e+00 - classifier_loss: 0.6528 - adversary_loss: -2.3809e+00 - val_loss: -7.0867e+00 - val_classifier_loss: 0.6475 - val_adversary_loss: -2.3637e+00\n",
      "Epoch 22/100\n",
      "128000/128000 - 2s - loss: -7.1411e+00 - classifier_loss: 0.6487 - adversary_loss: -2.3804e+00 - val_loss: -7.0865e+00 - val_classifier_loss: 0.6436 - val_adversary_loss: -2.3536e+00\n",
      "Epoch 23/100\n",
      "128000/128000 - 2s - loss: -7.1429e+00 - classifier_loss: 0.6446 - adversary_loss: -2.3802e+00 - val_loss: -7.0854e+00 - val_classifier_loss: 0.6405 - val_adversary_loss: -2.3579e+00\n",
      "Epoch 24/100\n",
      "128000/128000 - 2s - loss: -7.1429e+00 - classifier_loss: 0.6417 - adversary_loss: -2.3819e+00 - val_loss: -7.0879e+00 - val_classifier_loss: 0.6368 - val_adversary_loss: -2.3766e+00\n",
      "Epoch 25/100\n",
      "128000/128000 - 2s - loss: -7.1415e+00 - classifier_loss: 0.6390 - adversary_loss: -2.3814e+00 - val_loss: -7.0813e+00 - val_classifier_loss: 0.6344 - val_adversary_loss: -2.3550e+00\n",
      "Epoch 26/100\n",
      "128000/128000 - 2s - loss: -7.1323e+00 - classifier_loss: 0.6359 - adversary_loss: -2.3769e+00 - val_loss: -7.0837e+00 - val_classifier_loss: 0.6330 - val_adversary_loss: -2.3596e+00\n",
      "Epoch 27/100\n",
      "128000/128000 - 2s - loss: -7.1401e+00 - classifier_loss: 0.6333 - adversary_loss: -2.3800e+00 - val_loss: -7.0866e+00 - val_classifier_loss: 0.6295 - val_adversary_loss: -2.3670e+00\n",
      "Epoch 28/100\n",
      "128000/128000 - 2s - loss: -7.1411e+00 - classifier_loss: 0.6317 - adversary_loss: -2.3796e+00 - val_loss: -7.0876e+00 - val_classifier_loss: 0.6282 - val_adversary_loss: -2.3660e+00\n",
      "Epoch 29/100\n",
      "128000/128000 - 2s - loss: -7.1398e+00 - classifier_loss: 0.6300 - adversary_loss: -2.3819e+00 - val_loss: -7.0880e+00 - val_classifier_loss: 0.6255 - val_adversary_loss: -2.3580e+00\n",
      "Epoch 30/100\n",
      "128000/128000 - 2s - loss: -7.1431e+00 - classifier_loss: 0.6277 - adversary_loss: -2.3813e+00 - val_loss: -7.0868e+00 - val_classifier_loss: 0.6244 - val_adversary_loss: -2.3689e+00\n",
      "Epoch 31/100\n",
      "128000/128000 - 2s - loss: -7.1405e+00 - classifier_loss: 0.6265 - adversary_loss: -2.3804e+00 - val_loss: -7.0825e+00 - val_classifier_loss: 0.6223 - val_adversary_loss: -2.3619e+00\n",
      "Epoch 32/100\n",
      "128000/128000 - 2s - loss: -7.1412e+00 - classifier_loss: 0.6250 - adversary_loss: -2.3812e+00 - val_loss: -7.0873e+00 - val_classifier_loss: 0.6207 - val_adversary_loss: -2.3550e+00\n",
      "Epoch 33/100\n",
      "128000/128000 - 2s - loss: -7.1429e+00 - classifier_loss: 0.6231 - adversary_loss: -2.3811e+00 - val_loss: -7.0839e+00 - val_classifier_loss: 0.6182 - val_adversary_loss: -2.3600e+00\n",
      "Epoch 34/100\n",
      "128000/128000 - 2s - loss: -7.1412e+00 - classifier_loss: 0.6212 - adversary_loss: -2.3792e+00 - val_loss: -7.0856e+00 - val_classifier_loss: 0.6171 - val_adversary_loss: -2.3692e+00\n",
      "Epoch 35/100\n",
      "128000/128000 - 2s - loss: -7.1412e+00 - classifier_loss: 0.6196 - adversary_loss: -2.3810e+00 - val_loss: -7.0887e+00 - val_classifier_loss: 0.6156 - val_adversary_loss: -2.3618e+00\n",
      "Epoch 36/100\n",
      "128000/128000 - 2s - loss: -7.1403e+00 - classifier_loss: 0.6178 - adversary_loss: -2.3802e+00 - val_loss: -7.0835e+00 - val_classifier_loss: 0.6148 - val_adversary_loss: -2.3633e+00\n",
      "Epoch 37/100\n",
      "128000/128000 - 2s - loss: -7.1404e+00 - classifier_loss: 0.6169 - adversary_loss: -2.3789e+00 - val_loss: -7.0869e+00 - val_classifier_loss: 0.6137 - val_adversary_loss: -2.3616e+00\n",
      "Epoch 38/100\n",
      "128000/128000 - 2s - loss: -7.1429e+00 - classifier_loss: 0.6153 - adversary_loss: -2.3802e+00 - val_loss: -7.0857e+00 - val_classifier_loss: 0.6124 - val_adversary_loss: -2.3524e+00\n",
      "Epoch 39/100\n",
      "128000/128000 - 2s - loss: -7.1418e+00 - classifier_loss: 0.6134 - adversary_loss: -2.3807e+00 - val_loss: -7.0887e+00 - val_classifier_loss: 0.6094 - val_adversary_loss: -2.3678e+00\n",
      "Epoch 40/100\n",
      "128000/128000 - 2s - loss: -7.1428e+00 - classifier_loss: 0.6123 - adversary_loss: -2.3806e+00 - val_loss: -7.0865e+00 - val_classifier_loss: 0.6083 - val_adversary_loss: -2.3589e+00\n",
      "Epoch 41/100\n",
      "128000/128000 - 2s - loss: -7.1420e+00 - classifier_loss: 0.6108 - adversary_loss: -2.3811e+00 - val_loss: -7.0879e+00 - val_classifier_loss: 0.6072 - val_adversary_loss: -2.3638e+00\n",
      "Epoch 42/100\n",
      "128000/128000 - 2s - loss: -7.1365e+00 - classifier_loss: 0.6095 - adversary_loss: -2.3793e+00 - val_loss: -7.0879e+00 - val_classifier_loss: 0.6050 - val_adversary_loss: -2.3662e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/100\n",
      "128000/128000 - 2s - loss: -7.1422e+00 - classifier_loss: 0.6078 - adversary_loss: -2.3798e+00 - val_loss: -7.0724e+00 - val_classifier_loss: 0.6053 - val_adversary_loss: -2.3588e+00\n",
      "Epoch 44/100\n",
      "128000/128000 - 2s - loss: -7.1318e+00 - classifier_loss: 0.6067 - adversary_loss: -2.3783e+00 - val_loss: -7.0887e+00 - val_classifier_loss: 0.6036 - val_adversary_loss: -2.3637e+00\n",
      "Epoch 45/100\n",
      "128000/128000 - 2s - loss: -7.1426e+00 - classifier_loss: 0.6050 - adversary_loss: -2.3803e+00 - val_loss: -7.0876e+00 - val_classifier_loss: 0.6032 - val_adversary_loss: -2.3638e+00\n",
      "Epoch 46/100\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import keras\n",
    "import tensorflow\n",
    "import keras.backend as K\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "import layers\n",
    "\n",
    "print(\"keras version\")\n",
    "print(keras.__version__)\n",
    "print(\"tensorflow version\")\n",
    "print(tensorflow.__version__)\n",
    "\n",
    "\n",
    "def classifier(num_feat):\n",
    "    # Inputs\n",
    "    i = Input(shape = (num_feat,))\n",
    "    \n",
    "    # Hidden layers\n",
    "    x1 = Dense(24, activation = 'relu')(i)      \n",
    "    x2 = Dense(16, activation = 'relu')(x1)     \n",
    "    x3 = Dense(8, activation = 'relu')(x2)      \n",
    "    \n",
    "    # Output layer\n",
    "    o = Dense(1, activation = 'sigmoid')(x3)\n",
    "    \n",
    "    # Build NN classifier\n",
    "    return Model(inputs = i, outputs = o, name = 'classifier')\n",
    "\n",
    "\n",
    "def adversary(num_gmm):\n",
    "    # Inputs\n",
    "    i = Input(shape = (1,))\n",
    "    myy = Input(shape = (1,))\n",
    "    \n",
    "    # Hidden layers\n",
    "    x1 = Dense(200, activation = 'relu')(i)       \n",
    "    x2 = Dense(100, activation = 'relu')(x1)      \n",
    "    x3 = Dense(50, activation = 'relu')(x2)      \n",
    "    \n",
    "    # Gaussian mixture model (GMM) components\n",
    "    coeffs = Dense(num_gmm, activation='softmax')(x3)  # GMM coefficients sum to one\n",
    "    means  = Dense(num_gmm, activation='sigmoid')(x3)  # Means are on [0, 1]\n",
    "    widths = Dense(num_gmm, activation='softplus')(x3)  # Widths are positive\n",
    "    \n",
    "    # Posterior probability distribution function\n",
    "    pdf = layers.PosteriorLayer(num_gmm)([coeffs, means, widths, myy])\n",
    "\n",
    "    return Model(inputs = [i, myy], outputs = pdf, name = 'adversary')\n",
    "\n",
    "\n",
    "def combined(clf, adv, lambda_reg, lr_ratio):\n",
    "    # Inputs\n",
    "    clf_input = Input(shape = clf.layers[0].input_shape[0][1])\n",
    "    myy_input = Input(shape = (1,))\n",
    "    \n",
    "    # Classifier ouput\n",
    "    clf_output = clf(clf_input)\n",
    "    \n",
    "    # Gradient reversal\n",
    "    gradient_reversal = layers.GradientReversalLayer(lambda_reg * lr_ratio)(clf_output)\n",
    "    \n",
    "    # Adversary\n",
    "    adv_output = adv([gradient_reversal, myy_input])\n",
    "    \n",
    "    return Model(inputs=[clf_input, myy_input], outputs=[clf_output, adv_output], name='combined')\n",
    "\n",
    "\n",
    "def custom_loss(y_true, y_pred):\n",
    "    '''\n",
    "    Kullback-Leibler loss; maximises posterior p.d.f.\n",
    "    Equivalent to binary-cross-entropy for all y = 1\n",
    "    '''    \n",
    "    return -K.log(y_pred)\n",
    "\n",
    "\n",
    "np.random.seed(2)\n",
    "\n",
    "\n",
    "'''\n",
    "Data pre-processing\n",
    "'''\n",
    "# Import data\n",
    "#data = np.loadtxt('x.csv', delimiter = ',', skiprows=1)\n",
    "\n",
    "# Import data\n",
    "#data = np.loadtxt('data_nohead.csv', delimiter = ',',skiprows=1)\n",
    "data = np.genfromtxt('data.csv', delimiter = ',', skip_header=1, filling_values=0)\n",
    "\n",
    "myy = data[:,26]\n",
    "y = data[:,25]\n",
    "X = data[:,1:25]\n",
    "\n",
    "# Normalize X data\n",
    "normalize = StandardScaler()\n",
    "X = normalize.fit_transform(X)\n",
    "      \n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test, myy_train, myy_test = train_test_split(X, y, myy, test_size = 0.20, random_state = 5)\n",
    "\n",
    "# Rescale diphoton invariant mass to [0,1]\n",
    "sc_myy_train = myy_train - myy_train.min()\n",
    "sc_myy_train /= myy_train.max()\n",
    "\n",
    "\n",
    "'''\n",
    "Define parameters for combined network\n",
    "'''\n",
    "\n",
    "# Number of samples, features, epochs & batch size\n",
    "num_samples = X_train.shape[0]\n",
    "num_feat = X_train.shape[1]\n",
    "num_epochs = 100\n",
    "batch = 5000\n",
    "\n",
    "lambda_reg = 3             # Regularization parameter \n",
    "num_gmm = 5                # Number of GMM components\n",
    "lr = 1e-5                 # Relative learning rates for classifier and adversary\n",
    "\n",
    "loss_weights = [lr, lambda_reg]\n",
    "\n",
    "# Prepare sample weights (i.e. only do mass-decorrelation for background)\n",
    "sample_weight = [np.ones(num_samples, dtype=float), (y_train == 0).astype(float)]\n",
    "sample_weight[1] *= np.sum(sample_weight[0])/ np.sum(sample_weight[1])   \n",
    "\n",
    "\n",
    "'''\n",
    "Define classifier, adversary & combined network\n",
    "'''\n",
    "\n",
    "clf = classifier(num_feat)\n",
    "adv = adversary(num_gmm)\n",
    "ANN = combined(clf, adv, lambda_reg, lr)\n",
    "\n",
    "# Build & train combined model\n",
    "ANN.compile(optimizer='adam', loss=['binary_crossentropy', custom_loss], loss_weights = loss_weights)\n",
    "hist_ANN = ANN.fit([X_train, sc_myy_train], [y_train, np.ones_like(sc_myy_train)], \n",
    "                   sample_weight = sample_weight, epochs = num_epochs, batch_size = batch, \n",
    "                   validation_split = 0.2, verbose = 2)\n",
    "\n",
    "\n",
    "'''\n",
    "Generate plots & output files\n",
    "'''\n",
    "\n",
    "# Test set predictions\n",
    "y_pred = clf.predict(X_test).flatten()\n",
    "\n",
    "# Write myy, predictions and label to file\n",
    "res = np.array([myy_test.T, y_pred, y_test])\n",
    "np.savetxt('discriminant.csv', res.T, delimiter = ',')\n",
    "\n",
    "# Loss plot \n",
    "loss_train = hist_ANN.history['loss']\n",
    "loss_val = hist_ANN.history['val_loss']\n",
    "epochs = range(1,len(loss_train)+1)\n",
    "plt.plot(epochs, loss_train, 'g', label='Training loss')\n",
    "plt.plot(epochs, loss_val, 'b', label='Validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(frameon = False)\n",
    "plt.show()\n",
    "\n",
    "# Classifier loss plot\n",
    "clf_loss_train = hist_ANN.history['classifier_loss']\n",
    "clf_loss_val = hist_ANN.history['val_classifier_loss']\n",
    "plt.plot(epochs, clf_loss_train, 'g', label = 'Classifier training loss')\n",
    "plt.plot(epochs, clf_loss_val, 'b', label = 'Classifier validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(frameon = False)\n",
    "plt.show()\n",
    "\n",
    "# Adversary loss plot\n",
    "adv_loss_train = hist_ANN.history['adversary_loss']\n",
    "adv_loss_val = hist_ANN.history['val_adversary_loss']\n",
    "plt.plot(epochs, adv_loss_train, 'g', label = 'Adversary training loss')\n",
    "plt.plot(epochs, adv_loss_val, 'b', label = 'Adversary validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(frameon = False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb9cc29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
